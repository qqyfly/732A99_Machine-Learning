---
title: "Machine Learning Computer Lab 1 Block2 (Group A7)"
author: 
  - Qinyuan Qi(qinqi464)
  - Satya Sai Naga Jaya Koushik	Pilla (satpi345)
  - Daniele	Bozzoli(danbo826)  
date: "`r Sys.Date()`"
output: pdf_document
---

## Statement of Contribution
For Lab 1 Block 2, we decided to split the two assignments equally, Qinyuan and Bozzoli completed Assignment 1, 
Satya and Bozzoli completed Assignment 2, after which, for verification's sake, we completed
each other's assignments as well and validated our findings. The report was also compiled by three of us,
with each handling their respective assignments.

## Assignment 1: ENSEMBLE METHODS

### Answer:

```{r setup1, include=FALSE}
###########################  Init code For Assignment 1 ########################
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
set.seed(1234)
```

```{r 1.1,echo = FALSE,cache=TRUE}
###############  Assignment 1 Ensemble methods #################################
compare_method1 <- function(x1, x2) {
  return(x1 < x2)
}

compare_method2 <- function(x1, x2) {
  return(x1 < 0.5)
}

compare_method3 <- function(x1, x2) {
  return((x1 > 0.5 & x2 > 0.5) | (x1 < 0.5 & x2 < 0.5))
}

ensemble_method <- function(record_number, tree_number, node_size, compare_method) {
  # init data set (copy from pdf file)
  
  x1 <- runif(100)  
  x2 <- runif(100)

  trdata <- cbind(x1, x2)
  y <- as.numeric(compare_method(x1, x2))
  trlabels <- as.factor(y)
  trdata <- cbind(trdata, trlabels)
  
  # training the model using random forest
  rf_model <- randomForest( as.factor(trlabels) ~ ., 
                            data = trdata, 
                            ntree = tree_number,
                            nodesize = node_size, 
                            keep.forest = TRUE)


  x1 <- runif(record_number)
  x2 <- runif(record_number)
  tedata <- cbind(x1, x2)
  y <- as.numeric(compare_method(x1, x2))
  telabels <- as.factor(y)

  rf_pred <- predict(rf_model, newdata = tedata, type = "class")
  
  # calculate the misclassification rate  
  misclassification_rate <- 1- sum(diag(table(rf_pred ,telabels)))/length(rf_pred)

  return (misclassification_rate)
}

```
### Task 1: Learning Random forest with ntree= 1,10 and 100 trees, nodesize = 25, condition (x1 < x2) and keep.forest = TRUE

We can find from the result that as the number of trees grows, the misclassification rate will decrease.
This is because the more trees we have, the more robust the model will be. 


```{r 1.2,echo = FALSE,cache=TRUE}

################################################################################
# call the function
record_numbers <- c(100, 1000)
tree_numbers <- c(1, 10, 100)

node_size <- 25
# data record number = 100
result1 <- ensemble_method(record_numbers[1], tree_numbers[1], node_size, 
                          compare_method1)
result2 <- ensemble_method(record_numbers[1], tree_numbers[2], node_size, 
                          compare_method1)
result3 <- ensemble_method(record_numbers[1], tree_numbers[3], node_size, 
                          compare_method1)

misclassification_df <- data.frame(matrix(ncol = 2, nrow=0))
colnames(misclassification_df) <- c("tree_number", "misclassification_rate")

misclassification_df <- rbind(misclassification_df, data.frame("tree_number" = tree_numbers[1], "misclassification_rate" = result1))  
misclassification_df <- rbind(misclassification_df, data.frame("tree_number" = tree_numbers[2], "misclassification_rate" = result2))  
misclassification_df <- rbind(misclassification_df, data.frame("tree_number" = tree_numbers[3], "misclassification_rate" = result3))  

misclassification_df
```

### Task 2: Learning Random forest with ntree= 1,10 and 100 trees, nodesize = 25, condition (x1 < x2) and keep.forest = TRUE, run 1000 times

We can find from the result that as the number of trees grows, the mean and variance of the misclassification rate will decrease.
When the record number grows, the mean and variance of the misclassification rate will also decrease.

```{r 1.3,echo = FALSE,cache=TRUE}
################################################################################
# When we set node_size = 25 and record_numbers = 100 and 1000 and check x1 < x2 ,and tree_num = 1,10,100
# and run it 1000 times

misclassification_rates_1.1 <- rep(0, 1000)
misclassification_rates_10.1 <- rep(0, 1000)
misclassification_rates_100.1 <- rep(0, 1000)

misclassification_rates_1.2 <- rep(0, 1000)
misclassification_rates_10.2 <- rep(0, 1000)
misclassification_rates_100.2 <- rep(0, 1000)

node_size = 25
for (i in 1:1000) {

  # data record number = 100
  misclassification_rates_1.1[i] <- ensemble_method(record_numbers[1], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method1)
  misclassification_rates_10.1[i] <- ensemble_method(record_numbers[1], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method1)
  misclassification_rates_100.1[i] <- ensemble_method(record_numbers[1], 
                                                   tree_numbers[3], node_size, 
                                                compare_method1)
  # data record number = 1000
  misclassification_rates_1.2[i] <- ensemble_method(record_numbers[2], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method1)
  misclassification_rates_10.2[i] <- ensemble_method(record_numbers[2], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method1)
  misclassification_rates_100.2[i] <- ensemble_method(record_numbers[2], 
                                                   tree_numbers[3], node_size, 
                                                compare_method1)
}

misclassification_mean_var_df <- data.frame(matrix(ncol = 4, nrow=0))
colnames(misclassification_mean_var_df) <- c("tree_number", "record_number", "misclassification_mean", "misclassification_var") 

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_1.1),
                                                 "misclassification_var" = var(misclassification_rates_1.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_10.1),
                                                 "misclassification_var" = var(misclassification_rates_10.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_100.1),
                                                 "misclassification_var" = var(misclassification_rates_100.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_1.2),
                                                 "misclassification_var" = var(misclassification_rates_1.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_10.2),
                                                 "misclassification_var" = var(misclassification_rates_10.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_100.2),
                                                 "misclassification_var" = var(misclassification_rates_100.2)
                                                 ))

misclassification_mean_var_df
```

### Task 3: Learning Random forest with ntree= 1,10 and 100 trees, nodesize = 25, condition (x1 < 0.5) and keep.forest = TRUE, run 1000 times

Same as Task 2. but we also find that all the data, including mean and variance, are smaller than what we get when using condition (x1 < x2). 

```{r 1.4,echo = FALSE,cache=TRUE}
################################################################################
# When we set node_size = 25 and record_numbers = 100 and 1000 and check x1 < 0.5 ,and tree_num = 1,10,100
# and run it 1000 times

misclassification_rates_1.1 <- rep(0, 1000)
misclassification_rates_10.1 <- rep(0, 1000)
misclassification_rates_100.1 <- rep(0, 1000)

misclassification_rates_1.2 <- rep(0, 1000)
misclassification_rates_10.2 <- rep(0, 1000)
misclassification_rates_100.2 <- rep(0, 1000)

node_size = 25
for (i in 1:1000) {

  # data record number = 100
  misclassification_rates_1.1[i] <- ensemble_method(record_numbers[1], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method2)
  misclassification_rates_10.1[i] <- ensemble_method(record_numbers[1], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method2)
  misclassification_rates_100.1[i] <- ensemble_method(record_numbers[1], 
                                                   tree_numbers[3], node_size, 
                                                compare_method2)
  # data record number = 1000
  misclassification_rates_1.2[i] <- ensemble_method(record_numbers[2], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method2)
  misclassification_rates_10.2[i] <- ensemble_method(record_numbers[2], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method2)
  misclassification_rates_100.2[i] <- ensemble_method(record_numbers[2], 
                                                   tree_numbers[3], node_size, 
                                                compare_method2)
}

misclassification_mean_var_df <- data.frame(matrix(ncol = 4, nrow=0))
colnames(misclassification_mean_var_df) <- c("tree_number", "record_number", "misclassification_mean", "misclassification_var") 

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_1.1),
                                                 "misclassification_var" = var(misclassification_rates_1.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_10.1),
                                                 "misclassification_var" = var(misclassification_rates_10.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_100.1),
                                                 "misclassification_var" = var(misclassification_rates_100.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_1.2),
                                                 "misclassification_var" = var(misclassification_rates_1.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_10.2),
                                                 "misclassification_var" = var(misclassification_rates_10.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_100.2),
                                                 "misclassification_var" = var(misclassification_rates_100.2)
                                                 ))

misclassification_mean_var_df
```
### Task 4: Learning Random forest with ntree= 1,10 and 100 trees, nodesize = 12, condition ((x1 > 0.5 & x2 > 0.5) | (x1 < 0.5 & x2 < 0.5))  and keep.forest = TRUE, run 1000 times

Same as Task 2. We find that this condition is almost the same as condition (x1 < x2). 

But we also find that changing the node size to 12 will get a better result than node size = 25. 

node_size = 25

```{r 1.5,echo = FALSE,cache=TRUE}
################################################################################
# When we set node_size = 12 and record_numbers = 100 and check 
#((x1 > 0.5 & x2 > 0.5) | (x1 < 0.5 & x2 < 0.5)) , and run  it 1000 times

misclassification_rates_1.1 <- rep(0, 1000)
misclassification_rates_10.1 <- rep(0, 1000)
misclassification_rates_100.1 <- rep(0, 1000)

misclassification_rates_1.2 <- rep(0, 1000)
misclassification_rates_10.2 <- rep(0, 1000)
misclassification_rates_100.2 <- rep(0, 1000)

node_size = 25
for (i in 1:1000) {

  # data record number = 100
  misclassification_rates_1.1[i] <- ensemble_method(record_numbers[1], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method3)
  misclassification_rates_10.1[i] <- ensemble_method(record_numbers[1], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method3)
  misclassification_rates_100.1[i] <- ensemble_method(record_numbers[1], 
                                                   tree_numbers[3], node_size, 
                                                compare_method3)
  # data record number = 1000
  misclassification_rates_1.2[i] <- ensemble_method(record_numbers[2], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method3)
  misclassification_rates_10.2[i] <- ensemble_method(record_numbers[2], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method3)
  misclassification_rates_100.2[i] <- ensemble_method(record_numbers[2], 
                                                   tree_numbers[3], node_size, 
                                                compare_method3)
}

misclassification_mean_var_df <- data.frame(matrix(ncol = 4, nrow=0))
colnames(misclassification_mean_var_df) <- c("tree_number", "record_number", "misclassification_mean", "misclassification_var") 

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_1.1),
                                                 "misclassification_var" = var(misclassification_rates_1.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_10.1),
                                                 "misclassification_var" = var(misclassification_rates_10.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_100.1),
                                                 "misclassification_var" = var(misclassification_rates_100.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_1.2),
                                                 "misclassification_var" = var(misclassification_rates_1.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_10.2),
                                                 "misclassification_var" = var(misclassification_rates_10.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_100.2),
                                                 "misclassification_var" = var(misclassification_rates_100.2)
                                                 ))

misclassification_mean_var_df

```

node_size = 12

```{r 1.6,echo = FALSE,cache = TRUE}
################################################################################
# When we set node_size = 12 and record_numbers = 100 and check 
#((x1 > 0.5 & x2 > 0.5) | (x1 < 0.5 & x2 < 0.5)) , and run  it 1000 times

misclassification_rates_1.1 <- rep(0, 1000)
misclassification_rates_10.1 <- rep(0, 1000)
misclassification_rates_100.1 <- rep(0, 1000)

misclassification_rates_1.2 <- rep(0, 1000)
misclassification_rates_10.2 <- rep(0, 1000)
misclassification_rates_100.2 <- rep(0, 1000)

node_size = 12
for (i in 1:1000) {

  # data record number = 100
  misclassification_rates_1.1[i] <- ensemble_method(record_numbers[1], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method3)
  misclassification_rates_10.1[i] <- ensemble_method(record_numbers[1], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method3)
  misclassification_rates_100.1[i] <- ensemble_method(record_numbers[1], 
                                                   tree_numbers[3], node_size, 
                                                compare_method3)
  # data record number = 1000
  misclassification_rates_1.2[i] <- ensemble_method(record_numbers[2], 
                                                 tree_numbers[1], node_size, 
                                                 compare_method3)
  misclassification_rates_10.2[i] <- ensemble_method(record_numbers[2], 
                                                  tree_numbers[2], node_size, 
                                                  compare_method3)
  misclassification_rates_100.2[i] <- ensemble_method(record_numbers[2], 
                                                   tree_numbers[3], node_size, 
                                                compare_method3)
}

misclassification_mean_var_df <- data.frame(matrix(ncol = 4, nrow=0))
colnames(misclassification_mean_var_df) <- c("tree_number", "record_number", "misclassification_mean", "misclassification_var") 

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_1.1),
                                                 "misclassification_var" = var(misclassification_rates_1.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_10.1),
                                                 "misclassification_var" = var(misclassification_rates_10.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 100,
                                                 "misclassification_mean" = mean(misclassification_rates_100.1),
                                                 "misclassification_var" = var(misclassification_rates_100.1)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 1, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_1.2),
                                                 "misclassification_var" = var(misclassification_rates_1.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 10, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_10.2),
                                                 "misclassification_var" = var(misclassification_rates_10.2)
                                                 ))

misclassification_mean_var_df <- rbind(misclassification_mean_var_df, 
                                      data.frame("tree_number" = 100, 
                                                 "record_number" = 1000,
                                                 "misclassification_mean" = mean(misclassification_rates_100.2),
                                                 "misclassification_var" = var(misclassification_rates_100.2)
                                                 ))

misclassification_mean_var_df

```

### Task 5: What happens with the mean error rate when the number of trees in the random forest grows? Why?

According to the result, we can say that as the number of trees in the random forest gets larger, the mean value of classification will decrease.

This is because more trees will help to increase the robustness of the noisy data and increase stability.

As discussed above, decreasing the node size will increase the tree size which yields better results.


### Task 6: The third dataset represents a slightly more complicated classification problem than the first one. Still, you should get better performance for it when using sufficient trees in the random forest. Explain why you get better performance

By observing the graph, we can find that the third dataset is more complicated than the first one.

For real problems, we can not use a linear decision boundary to classify the data directly.
So it's better to use the third dataset to train the model.

Meanwhile, we can find that the misclassification rate of the third dataset is greater than the first one. 
Since the model gets complicated, we need to use a sufficient amount of trees to get better performance  and also 
prevent overfitting.

```{r 1.7,echo = FALSE}
set.seed(1234)
x1 <- runif(1000)
x2 <- runif(1000)

tedata <- cbind(x1, x2)
y <- as.numeric(compare_method1(x1, x2))
telabels <- as.factor(y)
plot(x1, x2, col = y+3, main = "First Dataset")

set.seed(5678)
x1 <- runif(1000)
x2 <- runif(1000)

tedata <- cbind(x1, x2)
y <- as.numeric(compare_method3(x1, x2))
telabels <- as.factor(y)
plot(x1, x2, col = y+3, main = "Third Dataset")

```

## Assignment 2: MIXTURE MODELS

### Answer:

```{r 2.0,echo = FALSE}
# define a function to implement the mixture model
mixel_model_fun <- function(M){
  w <- matrix(nrow = n, ncol = M) # weights
  pi <- vector(length = M) # mixing coefficients
  mu <- matrix(nrow = M, ncol = D) # conditional distributions
  llik <- vector(length = max_it) # log likelihood of the EM iterations

  # Random initialization of the parameters
  pi <- runif(M, 0.49, 0.51)
  pi <- pi / sum(pi)
  for (m in 1:M) {
    mu[m, ] <- runif(D, 0.49, 0.51)
  }

  par(mfrow=c(3,4),mar = c(1, 1, 1, 1))

  iterLog <- vector(length = max_it)

  for(it in 1:max_it) {
    plot(mu[1,], type="o", col="blue", ylim=c(0,1))
    points(mu[2,], type="o", col="red")
    if (M > 2){
        points(mu[3,], type="o", col="green")
    }
    if (M > 3){
        points(mu[4,], type="o", col="pink")
    }
    Sys.sleep(2)

    # E-step: Computation of the weights
    for (i in 1:n) {
        pxi <- 0
        for (m in 1:M) {
          bern <- 1
          for(d in 1:D) {
            bern <- bern * (mu[m,d]^x[i,d]) * (1-mu[m,d])^(1-x[i,d])          
          }
          pxi <- pxi + pi[m] * bern
        }

        for (m in 1:M) {
          bern <- 1
          for(d in 1:D) {
            bern <- bern * (mu[m,d]^x[i,d]) * (1-mu[m,d])^(1-x[i,d])          
          }
          w[i, m] <- pi[m] * bern / pxi
        }
        w[i,] <- w[i,] / sum(w[i,])
    }

    #Log likelihood computation.
    llik[it] <- 0
    for (i in 1:n) {
      pxi <- 0
      for (m in 1:M) {
        bern <- 1
        for(d in 1:D) {
          bern <- bern * (mu[m,d]^x[i,d]) * (1-mu[m,d])^(1-x[i,d])          
        }
        pxi <- pxi + pi[m] * bern
      }
      llik[it] <- llik[it] + log(pxi)
    }
    
    iterLog[it] <- paste("iteration is ", it, 
                        "log likelihood ", llik[it])

    flush.console()

    # Stop if the lok likelihood has not changed significantly
    if (it > 1 && abs(llik[it] - llik[it - 1]) < min_change) {
        break
    }

    pi <- apply(w,2,mean)
    mu <- t(w) %*% x / colSums(w)
  }

  par(mfrow=c(1,1),mar = c(1, 1, 1, 1))
  plot(llik[1:it], type = "o")
  print(iterLog[1:it])

  print("Pi value are")
  print(pi)
  print("Mu value are")
  print(mu)
}
```

We will generate the $\pi$ and $\mu$

```{r 2.1,echo = FALSE,cache=TRUE}
# init data set (copy from pdf file)
set.seed(1234567890)
# max number of EM iterations
max_it <- 100
# min change in log likelihood between two consecutive iterations
min_change <- 0.1
# number of training points
n <- 1000
# number of dimensions
D <- 10
# training data
x <- matrix(nrow = n, ncol = D)
# true mixing coefficients
true_pi <- vector(length = 3)
# true conditional distributions
true_mu <- matrix(nrow = 3, ncol = D)
true_pi <- c(1 / 3, 1 / 3, 1 / 3)
true_mu[1, ] <- c(0.5, 0.6, 0.4, 0.7, 0.3, 0.8, 0.2, 0.9, 0.1, 1)
true_mu[2, ] <- c(0.5, 0.4, 0.6, 0.3, 0.7, 0.2, 0.8, 0.1, 0.9, 0)
true_mu[3, ] <- c(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)
plot(true_mu[1, ], type = "o", col = "blue", ylim = c(0, 1))
points(true_mu[2, ], type = "o", col = "red")
points(true_mu[3, ], type = "o", col = "green")
```

```{r 2.2,echo = FALSE}

# Producing the training data
for(i in 1:n) {
  m <- sample(1:3, 1, prob = true_pi)
  for(d in 1:D) {
    x[i, d] <- rbinom(1, 1, true_mu[m, d])
  }
}
```
When M=2, we get the following result. Iteration runs 12 times, and the final
log likelihood is -6362.89725846549, $\pi$ values are[0.497125,0.502875].

The final shape is almost the same as the true $\mu$ shape after running 12 times.

```{r 2.3,echo = FALSE}
mixel_model_fun(M=2)
```

When M=3, we get the following result. Iteration runs 46 times, and the final
log likelihood is -6345.43095278126, $\pi$ values are[0.3964172,0.2787080,0.3248749].

The green and blue lines of the final shape are almost the same as the true $\mu$ shape after running 46 times.
but the red one is not.


```{r 2.4,echo = FALSE}
mixel_model_fun(M=3)
```

When M=4, we get the following result. Iteration runs 32 times, and the final
log likelihood is -6342.66757470638, $\pi$ values are [0.2690190,0.2863050,0.2457246,0.1989515].

The green and blue lines of the final shape are almost the same as the true $\mu$ shape after running 46 times.
but the red one is not.

```{r 2.5,echo = FALSE}
mixel_model_fun(M=4)
```

Above all, all likelihood plots show that it increases monotonically.
It increases sharply before the 7th iteration.
After that, the likelihood increases slowly.

Also as mentioned before, not all lines fit the true $\mu$ value well. especially when M=3 and 4.

\newpage
# Appendix: All code for this report

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
